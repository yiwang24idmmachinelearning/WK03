{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bigger Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Include some helper functions and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from data_utils import object_from_json_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load ANSUR 2 Databse\n",
        "\n",
        "The `JSON` file has a subset of the measurements found [here](https://www.openlab.psu.edu/ansur2/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ANSUR_JSON_URL = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur.json\"\n",
        "ansur = object_from_json_url(ANSUR_JSON_URL)\n",
        "\n",
        "# TODO: look at the data\n",
        "\n",
        "# Answer:\n",
        "#   - how many rows/records/items ?\n",
        "#   - longest ear ?\n",
        "#   - height of person with longest ear ?\n",
        "#   - tallest height ?\n",
        "#   - average height ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's look at a simpler versions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AHW_JSON_URL = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur_age_height_weight_object.json\"\n",
        "ahw_objs = object_from_json_url(AHW_JSON_URL)\n",
        "\n",
        "# TODO: look at data\n",
        "# How is it organized ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AHW_LIST_URL = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur_age_height_weight.json\"\n",
        "ahws = object_from_json_url(AHW_LIST_URL)\n",
        "\n",
        "# TODO: look at data\n",
        "# How is it organized ?\n",
        "\n",
        "# Answer the following:\n",
        "#   - how many items ?\n",
        "#   - how do we access the height of a person ?\n",
        "#   - tallest height ?\n",
        "#   - average height ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of Lists\n",
        "\n",
        "Just like we can put lists inside objects, and objects inside lists, we can also put lists inside lists.\n",
        "\n",
        "If we want to get to a particular value we have to use $2$ indices instead of using just one:\n",
        "`list[i][j]`\n",
        "\n",
        "The first index tells Python which of the sub-lists we want, and the second specifies the item on that list.\n",
        "\n",
        "<img src=\"./imgs/list-of-lists00.jpg\" width=\"700px\" />\n",
        "\n",
        "<img src=\"./imgs/list-of-lists01.jpg\" width=\"700px\" />\n",
        "\n",
        "Sometimes we'll refer to the first index as the row index and the second index as the column index.\n",
        "\n",
        "That's because if we imagine our list of lists as a 2-dimensional matrix of numbers, the first index tells Python which row we want to access and the second tells which column:\n",
        "\n",
        "<img src=\"./imgs/list-of-lists02.jpg\" width=\"700px\" />\n",
        "\n",
        "<img src=\"./imgs/list-of-lists03.jpg\" width=\"700px\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Datasets\n",
        "\n",
        "We'll see this kind of structure a lot.\n",
        "\n",
        "It's very common for datasets to be organized by rows/columns, where each column specifies a different *property* (or *feature*) and each row is a different *measurement* (or *record*) of those features.\n",
        "\n",
        "In our example above, our dataset had $3$ *features* (age, height, weight), and one *record* per person.\n",
        "\n",
        "<img src=\"./imgs/datasets00.jpg\" width=\"700px\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### JSON\n",
        "\n",
        "It's also common to find datasets specified in the JSON format.\n",
        "\n",
        "Instead of just being a list of lists with values, each *record* is an object that specifies the names and values of its *features*:\n",
        "\n",
        "<img src=\"./imgs/datasets01.jpg\" width=\"700px\" />\n",
        "\n",
        "There are advantages and disadvantages to each. We'll soon look at another way to organize datasets that will make it easier to go from one type to the other if we have to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n",
        "\n",
        "We can use the [matplot](https://matplotlib.org/stable/api/pyplot_summary.html) library to visualize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get heights\n",
        "heights = []\n",
        "\n",
        "plt.plot(heights, 'bo', markersize=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get weights\n",
        "weights = []\n",
        "\n",
        "plt.plot(weights, 'ro', markersize=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: plot ages in green\n",
        "ages = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sorting data can give a different perspective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_heights = sorted(heights)\n",
        "plt.plot(sorted_heights, 'bo', markersize=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_height = min(heights)\n",
        "max_height = max(heights)\n",
        "plt.hist(heights, bins=range(min_height, max_height + 1))\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation\n",
        "\n",
        "Measurement of how $2$ independent variables (features) are related to each other.\n",
        "\n",
        "<img src=\"./imgs/correlation.jpg\" width=\"800px\" />\n",
        "\n",
        "They can have *positive* or *direct* correlation, if an increase in one of the variables comes with an increase in the other.\n",
        "\n",
        "They can have *negative* or *inverse* correlation if an increase in one of the variables is accompanied by a decrease in the other.\n",
        "\n",
        "Or, there can be *weak* or *NO* correlation, if a change in one variable doesn't seem to be accompanied by a change in the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use \"column\" lists from above to plot scatter plot\n",
        "plt.scatter(ages, heights, marker='o', alpha=0.2)\n",
        "plt.xlabel(\"age\")\n",
        "plt.ylabel(\"height\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO plot other combinations of variables\n",
        "# TODO: any correlation ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Other Kinds of Lists\n",
        "\n",
        "## Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/audio_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wave\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "from audio_utils import wav_to_list, list_to_wav\n",
        "from audio_utils import fft, stft, cluster_fft_freqs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKGt8bzScNA"
      },
      "source": [
        "## Digital Audio\n",
        "\n",
        "Air pressure waves converted to electrical pulses, which are then sampled and turned into a sequence of numbers.\n",
        "\n",
        "<img src=\"./imgs/audio-00.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Playing an audio file\n",
        "\n",
        "Easy !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Audio(\"./data/two-bits.wav\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Look at the `data/` directory, and load and play some of the other files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: play other files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading an audio file for analysis, manipulation, etc\n",
        "\n",
        "is a bit more work. The Python [wave module](https://docs.python.org/3/library/wave.html) helps a lot, but there are still some steps that we have to take.\n",
        "\n",
        "Let's first open a `.wav` file and read it into a wave object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/air-horn.wav\"\n",
        "wav_in = wave.open(sound_file_path, mode=\"rb\")\n",
        "\n",
        "print(wav_in.getparams())\n",
        "display(Audio(sound_file_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Audio length, channels, samples, rate, depth\n",
        "\n",
        "<img src=\"./imgs/audio-01.jpg\" width=\"720px\">\n",
        "\n",
        "`Audio length`: The duration of an audio file in seconds. $Audio\\ Length = \\frac{Number\\ of\\ Samples}{Sample\\ Rate}$\n",
        "\n",
        "`Channels`: The different signals that make up an audio file.\n",
        "\n",
        "`Amplitude`: The strength of the audio signal. Related to volume.\n",
        "\n",
        "`Samples`: List of numbers that represent the amplitude of an audio signal at specific time intervals.\n",
        "\n",
        "`Frame`: Collection of samples from all channels at a given time. $Number\\ of\\ Frames = \\frac{Number\\ of\\ Samples}{Number\\ of\\ Channels}$\n",
        "\n",
        "`Sample Rate`: How many times per second the original audio signal was recorded. $Sample\\ Rate = \\frac{Number\\ of\\ Frames}{Audio\\ Length}$\n",
        "\n",
        "`Bit Depth` / `Sample Width`: How many different unique numbers are used to represent a sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Open some of the other files in the `data/` directory and print their parameters\n",
        "\n",
        "Do those make more sense now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: open and print params for some of the other files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Samples\n",
        "### Getting sample values\n",
        "\n",
        "We first have to open a `.wav` file with `wave.open()` to get a file object.\n",
        "\n",
        "We can then use the file object's `readframes()` function to read the file's contents into a buffer of `bytes`, and the `frombuffer()` function to turn a buffer of `bytes` into a list of `integers`.\n",
        "\n",
        "And, finally, we can use `list()` to put it all inside a regular Python list.\n",
        "\n",
        "<img src=\"./imgs/audio-02.jpg\" width=\"720px\">\n",
        "\n",
        "# ðŸ˜«\n",
        "\n",
        "That's a lot of cryptic lines of code just to open a file and get a list of numbers !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/western.wav\"\n",
        "wav_in = wave.open(sound_file_path, mode=\"rb\")\n",
        "read_buffer = wav_in.readframes(wav_in.getnframes())\n",
        "my_samples = list(np.frombuffer(read_buffer, dtype=np.int16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get number of samples\n",
        "There's a way to calculate the number of samples from the wave object's parameters.\n",
        "\n",
        "Can you get it from the `my_samples` list?\n",
        "\n",
        "What about the min and max sample values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get number of samples\n",
        "# TODO: get min/max sample values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing\n",
        "\n",
        "At least we can visualize it now using matplotlib and play it from the list of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "\n",
        "display(Audio(my_samples, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ˜«ðŸ˜«\n",
        "\n",
        "For sound files with more than one channel, the `Audio()` function expects the samples in a format that is different from the one returned by `wave.open()` and `wave.readframes()`.\n",
        "\n",
        "<img src=\"./imgs/wav-x-audio.jpg\" height=\"400px\">\n",
        "\n",
        "Argh!\n",
        "\n",
        "We can give `Audio()` every other sample and listen to just one of the channels.\n",
        "\n",
        "We could do this with a for-loop or list comprehension, but we can also use slicing with a third parameter.\n",
        "\n",
        "Just like the `range()` function can take a third parameter to specify the steps/skips in a sequence, we can use slice with a third parameter to step through the array by every other sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Audio(my_samples[::2], rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But, it's better to use a function to read our wave files and return a single-channel array that combines all of the channels in an audio file.\n",
        "\n",
        "The `wav_to_list()` function does exactly this:\n",
        "<br>It goes through the samples array and returns the average of the sample values for each frame.\n",
        "\n",
        "For a 2-channel audio file it sums every $2$ samples and divides that sum by $2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/western.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "# TODO : check the length of the samples array, and its min and max sample values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can plot and listen to the samples correctly and do any processing using only one list of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "\n",
        "display(Audio(my_samples, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ‘¯"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat the previous process for a different audio file\n",
        "Open an audio file and get a list of its samples.\n",
        "Play the audio to make sure it sounds like what you expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: read another file into an array of samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manipulating Audio\n",
        "\n",
        "Once we have a list of samples we can process, analyze and manipulate the audio by performing list operations and simple arithmetics.\n",
        "\n",
        "<img src=\"./imgs/audio-02.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change volume\n",
        "\n",
        "To change the volume of an audio file all we have to do is multiply its samples by a constant.\n",
        "\n",
        "If the constant is greater than $1$ it will get louder, if it's between $0$ and $1$ it will get softer.\n",
        "\n",
        "<img src=\"./imgs/audio-04.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process the samples array to makes the audio softer and then louder\n",
        "Check results visually and by listening to the audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/air-horn.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "\n",
        "# TODO: make samples softer and louder\n",
        "softer_samples = []\n",
        "louder_samples = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check modified samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check modified samples\n",
        "plt.plot(softer_samples)\n",
        "plt.show()\n",
        "\n",
        "display(Audio(softer_samples, rate=44100))\n",
        "\n",
        "# TODO: check louder samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change speed\n",
        "\n",
        "If we just duplicate each sample in our sequence, while keeping the sample rate the same, we'll end up with an audio file that is twice as long as the original.\n",
        "\n",
        "<img src=\"./imgs/audio-05.jpg\" width=\"720px\">\n",
        "\n",
        "And, conversely, if we remove every other sample, we'll get an audio signal that is half of the original length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process the samples array to makes the audio shorter and longer\n",
        "Check results visually and by listening to the audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/horn.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "print(len(my_samples), \"samples\")\n",
        "\n",
        "# TODO: double and half the samples to hear the effects\n",
        "double_samples = []\n",
        "half_samples = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check modified samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: check visually and by listening"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reverse\n",
        "\n",
        "Flipping the order of the samples will make the audio sound backwards.\n",
        "\n",
        "<img src=\"./imgs/audio-06.jpg\" width=\"720px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cell reverses the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sound_file_path = \"./data/two-bits.wav\"\n",
        "my_samples = wav_to_list(sound_file_path)\n",
        "\n",
        "rev_samples = list(reversed(my_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can check the effect running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_samples)\n",
        "plt.show()\n",
        "display(Audio(sound_file_path))\n",
        "print(my_samples[:16])\n",
        "\n",
        "plt.plot(rev_samples)\n",
        "plt.show()\n",
        "display(Audio(rev_samples, rate=44100))\n",
        "print(rev_samples[-16:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combining sounds\n",
        "\n",
        "To combine two audio signals, to have them play on top of each other, we just have to add every sample $S_{A_i}$ of our first audio file with it's corresponding sample in the second audio file $S_{B_i}$.\n",
        "\n",
        "<img src=\"./imgs/audio-07.jpg\" width=\"720px\">\n",
        "\n",
        "In this situation we can use the `zip()` function, which returns a sequence that is made up of pairs of elements from other sequences.\n",
        "\n",
        "For example, if we have:\n",
        "```python\n",
        "A = [10,11,12,13,14]\n",
        "B = [20,21,22,23,24]\n",
        "```\n",
        "\n",
        "then, `zip(A,B)` will give us this list:\n",
        "```python\n",
        "[(10,20), (11,21), (12,22), (13,23), (14,24)]\n",
        "```\n",
        "\n",
        "It's like a zipper, where it builds its elements from one element of each of its arguments.\n",
        "\n",
        "The `zip()` function is smart and will stop zipping once either of the two sequences runs out of samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use zip and the two sample sequences below to combine two sequences of samples\n",
        "We might have to soften the resulting sums to avoid distortions by guaranteeing that the samples don't get too loud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_bit_file_path = \"./data/two-bits.wav\"\n",
        "two_bit_samples = wav_to_list(two_bit_file_path)\n",
        "\n",
        "air_horn_file_path = \"./data/air-horn.wav\"\n",
        "air_horn_samples = wav_to_list(air_horn_file_path)\n",
        "\n",
        "plt.plot(two_bit_samples)\n",
        "plt.show()\n",
        "display(Audio(two_bit_file_path))\n",
        "print(len(two_bit_samples), \"samples\")\n",
        "\n",
        "plt.plot(air_horn_samples)\n",
        "plt.show()\n",
        "display(Audio(air_horn_file_path))\n",
        "print(len(air_horn_samples), \"samples\")\n",
        "\n",
        "# TODO: sum samples\n",
        "sum_samples = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check results of sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splicing\n",
        "\n",
        "Here we want to add the second wave after the first.\n",
        "\n",
        "In Python we can use addition to concatenate two lists:\n",
        "```python\n",
        "A = [0,1,2,3]\n",
        "B = [4,5,6,7]\n",
        "C = A + B\n",
        "```\n",
        "\n",
        "The `C` variable now holds `[0,1,2,3,4,5,6,7]`.\n",
        "\n",
        "We can also use slicing to select parts of the two sounds before adding them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_bit_file_path = \"./data/two-bits.wav\"\n",
        "two_bit_samples = wav_to_list(two_bit_file_path)\n",
        "\n",
        "air_horn_file_path = \"./data/air-horn.wav\"\n",
        "air_horn_samples = wav_to_list(air_horn_file_path)\n",
        "\n",
        "plt.plot(two_bit_samples)\n",
        "plt.show()\n",
        "display(Audio(two_bit_file_path))\n",
        "print(len(two_bit_samples), \"samples\")\n",
        "\n",
        "plt.plot(air_horn_samples)\n",
        "plt.show()\n",
        "display(Audio(air_horn_file_path))\n",
        "print(len(air_horn_samples), \"samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This sum just places the second audio right after the first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum_samples = two_bit_samples + air_horn_samples\n",
        "\n",
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This sum keeps $60\\%$ of the first audio and then starts the second audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "end_idx = int(0.6 * len(two_bit_samples))\n",
        "\n",
        "sum_samples = two_bit_samples[:end_idx] + air_horn_samples\n",
        "\n",
        "plt.plot(sum_samples)\n",
        "plt.show()\n",
        "display(Audio(sum_samples, rate=44100))\n",
        "print(len(sum_samples), \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving our samples\n",
        "\n",
        "We can use the `list_to_wav()` function to save a sequence of samples as a mono `.wav` file:\n",
        "\n",
        "```py\n",
        "list_to_wav(sum_samples, \"out.wav\")\n",
        "```\n",
        "\n",
        "### Save your favorite modified sample list as a wave file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: save a list of samples as a wav file\n",
        "# TODO: find it on the file explorer and download it to your computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Audio Analysis\n",
        "\n",
        "### Time-Domain\n",
        "\n",
        "There are a couple of simple analysis and transformations that we can perform on our samples to extract information about them and our audio signal as a whole.\n",
        "\n",
        "These are sometimes called _time-domain features_ because they are concerned with how an audio signal changes over time.\n",
        "\n",
        "Since the information we want to extract from the samples will hopefully tell us something about the audio's characteristic in terms of loudness or pitch, it's useful if we work with chunks of audio that are long enough for us to notice these properties.\n",
        "\n",
        "What this means is that we will further split our list of samples into smaller lists that contain about $10$ - $50$ milliseconds of audio.\n",
        "\n",
        "This process is sometimes called _windowing_ or _blocking_, and the result is a list of lists, where the outer list gives us a list of windows or blocks and the internal lists are just regular lists of samples:\n",
        "\n",
        "<img src=\"./imgs/window-00.jpg\" height=\"250px\">\n",
        "\n",
        "<img src=\"./imgs/window-01.jpg\" height=\"250px\">\n",
        "\n",
        "### Let's open up an audio file and split it into lists of 1024 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = \"./data/two-bits.wav\"\n",
        "all_samples = wav_to_list(file_path)\n",
        "\n",
        "# variable for number of samples per window, or, the window length\n",
        "WLEN = 1024\n",
        "\n",
        "# first sample index for each window: [ 0, 1024, 2048, 3072, 4096, ... ]\n",
        "wx = range(0, len(all_samples), WLEN)\n",
        "\n",
        "samples_win = []\n",
        "for s in wx:\n",
        "  samples_win.append(all_samples[s : s + WLEN])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Root Mean Square Energy\n",
        "\n",
        "Now that we have our list split into chunks/blocks/windows, we can calculate some properties for each of these windows.\n",
        "\n",
        "The first will be a measurement of loudness called the root mean square energy. This is calculated by taking the square root of the arithmetic mean of the squares of our sample values, or:\n",
        "\n",
        "$ rms = \\sqrt{\\frac{1}{n} ({s_0}^2 + {s_1}^2 + {s_2}^2 + ... + {s_{n-1}^2})}$\n",
        "\n",
        "<img src=\"./imgs/window-02.jpg\" height=\"250px\">\n",
        "\n",
        "### Let's write a function that implements this\n",
        "\n",
        "It will receive a list of samples and return their rms value.\n",
        "\n",
        "First we can calculate the squares of all the samples with a comprehension, then find the average value of this array $\\displaystyle \\left(\\frac{sum}{length}\\right)$, and finally take the square root.\n",
        "\n",
        "Remember that in python we can take the square root of a number $x$ by raising it to $0.5$, like `x ** 0.5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement rms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now, we'll use that to compute the rms for each of our windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compute the rms of each window in samples_win\n",
        "\n",
        "samples_rms = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we compare the length of our two arrays (`all_samples` and `samples_rms`) and also plot their contents, we'll see that even though one of them is 1000 times smaller, it's still able to represent enough information about how the loudness of the sound changes over time.\n",
        "\n",
        "This is good because if we wanted to compare it to other sounds to find similarities, instead of comparing $100,000$ values we can now compare $100$.\n",
        "\n",
        "We'll see more about this in the homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(all_samples), len(samples_rms))\n",
        "\n",
        "plt.plot(all_samples)\n",
        "plt.plot(wx, samples_rms, 'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zero-Crossing Rate\n",
        "\n",
        "Another time-domain feature we can extract from our samples is their zero-crossing rate, or, how frequently the wave change from a positive value to a negative one.\n",
        "\n",
        "<img src=\"./imgs/window-04.jpg\" height=\"250px\">\n",
        "\n",
        "This can give us some idea about the frequency of our sound at different points in time because higher tones, with higher frequencies, tend to have higher zero-crossing rates.\n",
        "\n",
        "The formula for computing the zero-crossing rate for a window of samples is:\n",
        "\n",
        "$\\displaystyle zcr = \\frac{1}{2} \\sum{\\left|{\\frac{|s_n|}{s_n} - \\frac{|s_{n+1}|}{s_{n+1}}} \\right|}$\n",
        "\n",
        "This looks more complicated than it should.\n",
        "\n",
        "The first thing we do is determine the sign of each sample. That's what the $\\displaystyle \\frac{|s_n|}{s_n}$ calculation does. It gives us a $+1$ if our sample is a positive number, $-1$ if it's a negative number and $0$ if the sample is $0$.\n",
        "\n",
        "Then we look at pairs of consecutive samples and subtract their signs. We'll get a $-2$ if the signal goes from a negative number to a positive number and a $+2$ if it goes from positive to negative.\n",
        "\n",
        "Finally, we sum up the absolute value of all of these $+2$ and $-2$ values and divide by $2$.\n",
        "\n",
        "### Let's write a function that implements this\n",
        "\n",
        "It will receive a list of samples and return the number of times the values change sign.\n",
        "\n",
        "We'll also implement a separate `sign()` function to do the $\\displaystyle \\frac{|s_n|}{s_n}$ calculation with a little bit of filtering to avoid counting zero-cross rates for noisy and quiet parts of of audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sign(sample):\n",
        "  if abs(sample) < 256:\n",
        "    return 0\n",
        "  else:\n",
        "    return (abs(sample) / sample)\n",
        "\n",
        "def zcr(samples):\n",
        "  signs = [sign(s) for s in samples]\n",
        "\n",
        "  twos = []\n",
        "  for i in range(0, len(samples) - 1):\n",
        "    sign_diff = signs[i] - signs[i+1]\n",
        "    twos.append(abs(sign_diff))\n",
        "\n",
        "  return (sum(twos) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now, we can use that to compute the zero-crossing rate for each of our windows\n",
        "\n",
        "We can then also plot this result overlaid with the original wave and rms plots.\n",
        "\n",
        "We might have to scale the `zcr()` results to make them comparable in scale to the original sample values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compute the zcr of each window in samples_win \n",
        "# and plot the results along with the original wave and rms plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat the time-domain feature extraction for another audio file\n",
        "\n",
        "Open the file and get a list of samples, then do the windowing, the rms analysis and the zero-crossing rate calculation, and plot the results.\n",
        "\n",
        "How do they compare to the `two-bits.wav` file ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat analysis with different file\n",
        "file_path = \"\"\n",
        "\n",
        "all_samples = []\n",
        "\n",
        "# first index of each window\n",
        "wx = range(0, len(all_samples), WLEN)\n",
        "\n",
        "samples_win = []\n",
        "samples_rms = []\n",
        "samples_zcr = []\n",
        "\n",
        "# TODO: plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frequency-Domain\n",
        "\n",
        "We saw that the zero-crossing rate can sometimes tell us something about the pitch of a sound, but there's a better way to get frequency information from a sound signal.\n",
        "\n",
        "There's a mathematical operation called a Fourier Transform that we can use to decompose our audio signal into simpler, basic waves of pure frequencies.\n",
        "\n",
        "A complex audio wave made up of many frequencies:<br>\n",
        "<img src=\"./imgs/fft-00.jpg\" width=\"600px\">\n",
        "\n",
        "Gets separated into sine waves of single frequencies:<br>\n",
        "<img src=\"./imgs/fft-01.jpg\" width=\"600px\">\n",
        "\n",
        "This is useful because it can tell us which frequencies are present in our audio at any given time.\n",
        "\n",
        "The math is a bit beyond our scope here, but luckily there are many packages and libraries that implement the  Fast Fourier Transform algorithm for extracting frequency information from audio waves, and its inverse, the `IFFT`, which is used for transforming frequency information back into sound waves.\n",
        "\n",
        "### Let's open up a file, read its samples and run the fft()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = \"./data/two-bits.wav\"\n",
        "all_samples = wav_to_list(file_path)\n",
        "\n",
        "fft_energy, fft_freqs = fft(all_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the `fft()` on an array of samples returns two lists: one with the amount of energy in different frequency bands, and the other with the specific values of the frequency bands (in units of Hertz).\n",
        "\n",
        "We can then plot these to get information about the frequencies present in our sound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(all_samples)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(fft_freqs, fft_energy)\n",
        "plt.xlabel('Freq (Hz)')\n",
        "plt.ylabel('FFT Energy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's zoom in on the x-axis since it doesn't look like we have any frequencies less than $200$ Hz or greater than $1000$ Hz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(fft_freqs, fft_energy)\n",
        "plt.xlabel('Freq (Hz)')\n",
        "plt.ylabel('FFT Energy')\n",
        "plt.xlim(200, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can combine the two arrays that we got from `fft()` and sort them to get a list of the more prevalent frequencies.\n",
        "\n",
        "First we'll combine them using zip, then sort by the fft energy values by using a key function.\n",
        "\n",
        "We'll also round the frequencies to the nearest Hz just to make it easier to analyze the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fft_energy_freq = [(round(f), e) for f,e in zip(fft_freqs, fft_energy)]\n",
        "\n",
        "def byFft(A):\n",
        "  return A[1]\n",
        "\n",
        "fft_sorted = sorted(fft_energy_freq, key=byFft, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we just look at the first 5 elements of the resulting array we'll see that they all have pretty similar frequencies.\n",
        "\n",
        "Must be a very strong component of the original signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fft_sorted[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Other frequencies ?\n",
        "\n",
        "Take a look at other parts of the list and see which additional frequencies are dominant in our audio signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Look into list for other frequencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the top-100 strongest frequencies in a scatter plot to see how these (energy, frequency) pairs are distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_freqs = [x[0] for x in fft_sorted[:100]]\n",
        "top_energy = [x[1] for x in fft_sorted[:100]]\n",
        "plt.scatter(top_freqs, top_energy)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And if we only plot the frequencies along a diagonal, we can see some pretty well-defined frequency clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(top_freqs, top_freqs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clustering\n",
        "\n",
        "We'll see a lot more about this in a few weeks, but this is a perfect situation where we can use a Machine Learning technique called clustering to \"learn\" how to combine similar frequencies into representative groups.\n",
        "\n",
        "The `cluster_fft_freqs()` function takes a list of fft frequency values and another list of the corresponding energy at each of those frequencies, and then calculates frequency cluster groups.\n",
        "\n",
        "There are additional optional parameters that we can use to tune this function.\n",
        "\n",
        "The `top` parameter can be used to determine how many of the top frequencies we want to use to do the clustering. The default is $50$, but since we looked at the top-100 strongest frequencies a few cells above, we can use $100$ for this parameter.\n",
        "\n",
        "Another parameter, `clusters`, can be used to specify how many groups we want to combine our data into. The default is $6$. From looking at the graphs above, maybe we can try $7$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_fft_freqs(fft_freqs, fft_energy, top=100, clusters=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat the `FFT` analysis and get the strongest $n$ frequencies in the `horn` audio file.\n",
        "\n",
        "For the horn file $n$ might be different than 7. Once we start plotting we'll see how many clusters we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat FFT on horn.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### STFT\n",
        "\n",
        "We can run a windowed version of the `FFT` on our samples to see which frequencies are present at different times. This is called a Short-Time Fourier Transform (`STFT`) because instead of running on the entire audio at once, it runs the `FFT` on small chunks/windows of audio.\n",
        "\n",
        "Running the `stft()` on an array of samples returns three lists: one with the amount of energy in different frequency bands, at specific times, another with the specific value for the frequency bands, and a third with the specific times when the `FFT` was performed (the chunk/window time).\n",
        "\n",
        "We can plot these to get information about the frequencies present in our sound at different times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fft_res, fft_freqs, fft_times = stft(all_samples)\n",
        "\n",
        "plt.pcolormesh(fft_times, fft_freqs, np.array(fft_res).T)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see some frequency activity on the lower frequencies.\n",
        "\n",
        "Let's zoom in on frequencies less than $2500$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.pcolormesh(fft_times, fft_freqs, np.array(fft_res).T)\n",
        "plt.ylim(0, 2500)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can definitely see where each of the notes are being played and how their pitch is related to each other.\n",
        "\n",
        "For now we'll only take this quick look at the `STFT`. It can be a bit harder to use for analysis and comparisons since it has $3$ dimensions of values (time, frequency, energy), but we'll get back to it in a couple of weeks and see how it can be used in more complex Machine Learning tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
